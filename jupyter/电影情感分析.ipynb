{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "movie_reviews_data_folder = r'.\\movie_review'\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False,encoding='utf8')\n",
    "# print(\"n_samples: %d\" % len(dataset.data))\n",
    "RANDOM_STATE=940302\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.2, random_state=RANDOM_STATE,shuffle=True)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# clf_pipe = Pipeline([\n",
    "#     ('vect',CountVectorizer()),\n",
    "#     ('tfidf',TfidfTransformer()),\n",
    "#     ('clf',SGDClassifier())])\n",
    "\n",
    "# clf_pipe.fit(docs_train,y_train)\n",
    "# y_pre = clf_pipe.predict(docs_test)\n",
    "# import numpy as np\n",
    "# np.mean(y_pre==y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.6846149 ,  0.65458536,  0.66853476,  2.96273073,  3.08042979,\n",
      "        2.98036615]), 'std_fit_time': array([ 0.03108948,  0.00376383,  0.00857129,  0.1027057 ,  0.1181902 ,\n",
      "        0.01864673]), 'mean_score_time': array([ 0.30867227,  0.28258952,  0.27658073,  0.72772272,  0.72240257,\n",
      "        0.70943634]), 'std_score_time': array([ 0.02721284,  0.00892447,  0.00571772,  0.01502258,  0.01356086,\n",
      "        0.02194635]), 'param_step1__ngram_range': masked_array(data = [(1, 1) (1, 1) (1, 1) (1, 2) (1, 2) (1, 2)],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__alpha': masked_array(data = [0.1 0.01 0.001 0.1 0.01 0.001],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'step1__ngram_range': (1, 1), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.001}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.001}], 'split0_test_score': array([ 0.77902622,  0.75655431,  0.72659176,  0.83146067,  0.80337079,\n",
      "        0.80337079]), 'split1_test_score': array([ 0.79174484,  0.76172608,  0.72983114,  0.81988743,  0.8011257 ,\n",
      "        0.78424015]), 'split2_test_score': array([ 0.79924953,  0.78236398,  0.75609756,  0.82739212,  0.8011257 ,\n",
      "        0.78424015]), 'mean_test_score': array([ 0.79    ,  0.766875,  0.7375  ,  0.82625 ,  0.801875,  0.790625]), 'std_test_score': array([ 0.008349  ,  0.01114904,  0.01321068,  0.00479394,  0.00105867,\n",
      "        0.00902108]), 'rank_test_score': array([4, 5, 6, 1, 2, 3]), 'split0_train_score': array([ 0.99530957,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split1_train_score': array([ 0.99531396,  0.99906279,  0.99906279,  1.        ,  1.        ,  1.        ]), 'split2_train_score': array([ 0.99437676,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'mean_train_score': array([ 0.9950001,  0.9996876,  0.9996876,  1.       ,  1.       ,  1.       ]), 'std_train_score': array([ 0.00044077,  0.0004418 ,  0.0004418 ,  0.        ,  0.        ,  0.        ])}\n",
      "==========================\n",
      "最佳分数：0.82625\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "# more useful.\n",
    "# Fit the pipeline on the training set using grid search for the parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipe_clf = Pipeline([('step1',TfidfVectorizer()), ('step2', MultinomialNB())])\n",
    "params={'step1__ngram_range':[(1,1),(1,2)],\n",
    "       'step2__alpha':(1e-1,1e-2,1e-3),\n",
    "       }\n",
    "gds = GridSearchCV(estimator=pipe_clf,param_grid=params)\n",
    "gds = gds.fit(docs_train,y_train)\n",
    "print(gds.cv_results_)\n",
    "print('==========================')\n",
    "print('最佳分数：{}'.format(gds.best_score_))                                  \n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gds.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵：\n",
      "[[155  35]\n",
      " [ 37 173]]\n",
      "---------------------------------------------------------------\n",
      "{'mean_fit_time': array([ 0.6846149 ,  0.65458536,  0.66853476,  2.96273073,  3.08042979,\n",
      "        2.98036615]), 'std_fit_time': array([ 0.03108948,  0.00376383,  0.00857129,  0.1027057 ,  0.1181902 ,\n",
      "        0.01864673]), 'mean_score_time': array([ 0.30867227,  0.28258952,  0.27658073,  0.72772272,  0.72240257,\n",
      "        0.70943634]), 'std_score_time': array([ 0.02721284,  0.00892447,  0.00571772,  0.01502258,  0.01356086,\n",
      "        0.02194635]), 'param_step1__ngram_range': masked_array(data = [(1, 1) (1, 1) (1, 1) (1, 2) (1, 2) (1, 2)],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__alpha': masked_array(data = [0.1 0.01 0.001 0.1 0.01 0.001],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'step1__ngram_range': (1, 1), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.001}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.001}], 'split0_test_score': array([ 0.77902622,  0.75655431,  0.72659176,  0.83146067,  0.80337079,\n",
      "        0.80337079]), 'split1_test_score': array([ 0.79174484,  0.76172608,  0.72983114,  0.81988743,  0.8011257 ,\n",
      "        0.78424015]), 'split2_test_score': array([ 0.79924953,  0.78236398,  0.75609756,  0.82739212,  0.8011257 ,\n",
      "        0.78424015]), 'mean_test_score': array([ 0.79    ,  0.766875,  0.7375  ,  0.82625 ,  0.801875,  0.790625]), 'std_test_score': array([ 0.008349  ,  0.01114904,  0.01321068,  0.00479394,  0.00105867,\n",
      "        0.00902108]), 'rank_test_score': array([4, 5, 6, 1, 2, 3]), 'split0_train_score': array([ 0.99530957,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split1_train_score': array([ 0.99531396,  0.99906279,  0.99906279,  1.        ,  1.        ,  1.        ]), 'split2_train_score': array([ 0.99437676,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'mean_train_score': array([ 0.9950001,  0.9996876,  0.9996876,  1.       ,  1.       ,  1.       ]), 'std_train_score': array([ 0.00044077,  0.0004418 ,  0.0004418 ,  0.        ,  0.        ,  0.        ])}\n",
      "==========================\n",
      "最佳分数：0.82625\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set and store it in a variable\n",
    "# named y_predicted\n",
    "y_predicted = gds.predict(docs_test)\n",
    "print('混淆矩阵：\\n{}'.format(metrics.confusion_matrix(y_predicted,y_test)))\n",
    "# Print the classification report\n",
    "print('---------------------------------------------------------------')\n",
    "def pipecv_report(clf,params):\n",
    "    print(clf.cv_results_)\n",
    "    print('==========================')\n",
    "    print('最佳分数：{}'.format(clf.best_score_))                                  \n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"%s: %r\" % (param_name, clf.best_params_[param_name]))\n",
    "        \n",
    "pipecv_report(gds,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.72811357, 0.68135198, 3.08693345, 3.00028515, 0.69230858,\n",
      "       0.6706934 , 3.04959941, 2.97755941]), 'std_fit_time': array([0.03591782, 0.00753077, 0.06320311, 0.01958779, 0.01801354,\n",
      "       0.00826088, 0.02621912, 0.02640809]), 'mean_score_time': array([0.31064677, 0.28937125, 0.72003667, 0.72669872, 0.28664978,\n",
      "       0.29333266, 0.71466899, 0.72943727]), 'std_score_time': array([0.04054738, 0.00817614, 0.00866117, 0.02623995, 0.01643976,\n",
      "       0.00822236, 0.01236596, 0.01364171]), 'param_step1__max_df': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_step1__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2),\n",
      "                   (1, 2)],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_step2__C': masked_array(data=[1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'step1__max_df': 0.6, 'step1__ngram_range': (1, 1), 'step2__C': 1.0}, {'step1__max_df': 0.6, 'step1__ngram_range': (1, 1), 'step2__C': 0.5}, {'step1__max_df': 0.6, 'step1__ngram_range': (1, 2), 'step2__C': 1.0}, {'step1__max_df': 0.6, 'step1__ngram_range': (1, 2), 'step2__C': 0.5}, {'step1__max_df': 0.7, 'step1__ngram_range': (1, 1), 'step2__C': 1.0}, {'step1__max_df': 0.7, 'step1__ngram_range': (1, 1), 'step2__C': 0.5}, {'step1__max_df': 0.7, 'step1__ngram_range': (1, 2), 'step2__C': 1.0}, {'step1__max_df': 0.7, 'step1__ngram_range': (1, 2), 'step2__C': 0.5}], 'split0_test_score': array([0.82209738, 0.82771536, 0.84082397, 0.84082397, 0.82771536,\n",
      "       0.82771536, 0.84456929, 0.84456929]), 'split1_test_score': array([0.82926829, 0.82363977, 0.85178236, 0.85178236, 0.82551595,\n",
      "       0.82363977, 0.84990619, 0.85178236]), 'split2_test_score': array([0.83114447, 0.84052533, 0.84803002, 0.8424015 , 0.81988743,\n",
      "       0.84052533, 0.85178236, 0.83677298]), 'mean_test_score': array([0.8275  , 0.830625, 0.846875, 0.845   , 0.824375, 0.830625,\n",
      "       0.84875 , 0.844375]), 'std_test_score': array([0.00389972, 0.00719247, 0.0045483 , 0.00483669, 0.00329639,\n",
      "       0.00719247, 0.00305645, 0.00612718]), 'rank_test_score': array([7, 5, 2, 3, 8, 5, 1, 4]), 'split0_train_score': array([1., 1., 1., 1., 1., 1., 1., 1.]), 'split1_train_score': array([1., 1., 1., 1., 1., 1., 1., 1.]), 'split2_train_score': array([1., 1., 1., 1., 1., 1., 1., 1.]), 'mean_train_score': array([1., 1., 1., 1., 1., 1., 1., 1.]), 'std_train_score': array([0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "#运行pipe2 要reload dataset\n",
    "# pipe_2 = Pipeline([('step1',TfidfVectorizer()), ('step2', SGDClassifier(random_state=940302,\n",
    "#                                            max_iter=200, tol=None))])\n",
    "\n",
    "pipe_2 = Pipeline([('step1',TfidfVectorizer()), ('step2',LinearSVC())])\n",
    "pipe_2_params={'step1__ngram_range':[(1,1),(1,2)],\n",
    "                'step1__max_df': (0.6,0.7),\n",
    "              'step2__C':(1.0,0.5)\n",
    "       }\n",
    "gds_2 = GridSearchCV(estimator=pipe_2,param_grid=pipe_2_params)\n",
    "gds_2 = gds_2.fit(docs_train,y_train)\n",
    "print(gds_2.cv_results_)\n",
    "print('==========================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳分数：0.84875\n",
      "step1__max_df: 0.7\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__C: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.84      0.85       192\n",
      "        pos       0.86      0.88      0.87       208\n",
      "\n",
      "avg / total       0.86      0.86      0.86       400\n",
      "\n",
      "0.8625\n"
     ]
    }
   ],
   "source": [
    "print('最佳分数：{}'.format(gds_2.best_score_))                                  \n",
    "for param_name in sorted(pipe_2_params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gds_2.best_params_[param_name]))\n",
    "y_predicted = gds_2.predict(docs_test)\n",
    "print(metrics.classification_report(y_test, y_predicted,target_names=dataset.target_names))\n",
    "print(metrics.accuracy_score(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
