{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "movie_reviews_data_folder = r'.\\movie_review'\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False,encoding='utf8')\n",
    "# print(\"n_samples: %d\" % len(dataset.data))\n",
    "RANDOM_STATE=940302\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.2, random_state=RANDOM_STATE)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# clf_pipe = Pipeline([\n",
    "#     ('vect',CountVectorizer()),\n",
    "#     ('tfidf',TfidfTransformer()),\n",
    "#     ('clf',SGDClassifier())])\n",
    "\n",
    "# clf_pipe.fit(docs_train,y_train)\n",
    "# y_pre = clf_pipe.predict(docs_test)\n",
    "# import numpy as np\n",
    "# np.mean(y_pre==y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.6846149 ,  0.65458536,  0.66853476,  2.96273073,  3.08042979,\n",
      "        2.98036615]), 'std_fit_time': array([ 0.03108948,  0.00376383,  0.00857129,  0.1027057 ,  0.1181902 ,\n",
      "        0.01864673]), 'mean_score_time': array([ 0.30867227,  0.28258952,  0.27658073,  0.72772272,  0.72240257,\n",
      "        0.70943634]), 'std_score_time': array([ 0.02721284,  0.00892447,  0.00571772,  0.01502258,  0.01356086,\n",
      "        0.02194635]), 'param_step1__ngram_range': masked_array(data = [(1, 1) (1, 1) (1, 1) (1, 2) (1, 2) (1, 2)],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__alpha': masked_array(data = [0.1 0.01 0.001 0.1 0.01 0.001],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'step1__ngram_range': (1, 1), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.001}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.001}], 'split0_test_score': array([ 0.77902622,  0.75655431,  0.72659176,  0.83146067,  0.80337079,\n",
      "        0.80337079]), 'split1_test_score': array([ 0.79174484,  0.76172608,  0.72983114,  0.81988743,  0.8011257 ,\n",
      "        0.78424015]), 'split2_test_score': array([ 0.79924953,  0.78236398,  0.75609756,  0.82739212,  0.8011257 ,\n",
      "        0.78424015]), 'mean_test_score': array([ 0.79    ,  0.766875,  0.7375  ,  0.82625 ,  0.801875,  0.790625]), 'std_test_score': array([ 0.008349  ,  0.01114904,  0.01321068,  0.00479394,  0.00105867,\n",
      "        0.00902108]), 'rank_test_score': array([4, 5, 6, 1, 2, 3]), 'split0_train_score': array([ 0.99530957,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split1_train_score': array([ 0.99531396,  0.99906279,  0.99906279,  1.        ,  1.        ,  1.        ]), 'split2_train_score': array([ 0.99437676,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'mean_train_score': array([ 0.9950001,  0.9996876,  0.9996876,  1.       ,  1.       ,  1.       ]), 'std_train_score': array([ 0.00044077,  0.0004418 ,  0.0004418 ,  0.        ,  0.        ,  0.        ])}\n",
      "==========================\n",
      "最佳分数：0.82625\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "# more useful.\n",
    "# Fit the pipeline on the training set using grid search for the parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipe_clf = Pipeline([('step1',TfidfVectorizer()), ('step2', MultinomialNB())])\n",
    "params={'step1__ngram_range':[(1,1),(1,2)],\n",
    "       'step2__alpha':(1e-1,1e-2,1e-3),\n",
    "       }\n",
    "gds = GridSearchCV(estimator=pipe_clf,param_grid=params)\n",
    "gds = gds.fit(docs_train,y_train)\n",
    "print(gds.cv_results_)\n",
    "print('==========================')\n",
    "print('最佳分数：{}'.format(gds.best_score_))                                  \n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gds.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵：\n",
      "[[155  35]\n",
      " [ 37 173]]\n",
      "---------------------------------------------------------------\n",
      "{'mean_fit_time': array([ 0.6846149 ,  0.65458536,  0.66853476,  2.96273073,  3.08042979,\n",
      "        2.98036615]), 'std_fit_time': array([ 0.03108948,  0.00376383,  0.00857129,  0.1027057 ,  0.1181902 ,\n",
      "        0.01864673]), 'mean_score_time': array([ 0.30867227,  0.28258952,  0.27658073,  0.72772272,  0.72240257,\n",
      "        0.70943634]), 'std_score_time': array([ 0.02721284,  0.00892447,  0.00571772,  0.01502258,  0.01356086,\n",
      "        0.02194635]), 'param_step1__ngram_range': masked_array(data = [(1, 1) (1, 1) (1, 1) (1, 2) (1, 2) (1, 2)],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__alpha': masked_array(data = [0.1 0.01 0.001 0.1 0.01 0.001],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'step1__ngram_range': (1, 1), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.001}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.1}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.01}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.001}], 'split0_test_score': array([ 0.77902622,  0.75655431,  0.72659176,  0.83146067,  0.80337079,\n",
      "        0.80337079]), 'split1_test_score': array([ 0.79174484,  0.76172608,  0.72983114,  0.81988743,  0.8011257 ,\n",
      "        0.78424015]), 'split2_test_score': array([ 0.79924953,  0.78236398,  0.75609756,  0.82739212,  0.8011257 ,\n",
      "        0.78424015]), 'mean_test_score': array([ 0.79    ,  0.766875,  0.7375  ,  0.82625 ,  0.801875,  0.790625]), 'std_test_score': array([ 0.008349  ,  0.01114904,  0.01321068,  0.00479394,  0.00105867,\n",
      "        0.00902108]), 'rank_test_score': array([4, 5, 6, 1, 2, 3]), 'split0_train_score': array([ 0.99530957,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split1_train_score': array([ 0.99531396,  0.99906279,  0.99906279,  1.        ,  1.        ,  1.        ]), 'split2_train_score': array([ 0.99437676,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'mean_train_score': array([ 0.9950001,  0.9996876,  0.9996876,  1.       ,  1.       ,  1.       ]), 'std_train_score': array([ 0.00044077,  0.0004418 ,  0.0004418 ,  0.        ,  0.        ,  0.        ])}\n",
      "==========================\n",
      "最佳分数：0.82625\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set and store it in a variable\n",
    "# named y_predicted\n",
    "y_predicted = gds.predict(docs_test)\n",
    "print('混淆矩阵：\\n{}'.format(metrics.confusion_matrix(y_predicted,y_test)))\n",
    "# Print the classification report\n",
    "print('---------------------------------------------------------------')\n",
    "def pipecv_report(clf,params):\n",
    "    print(clf.cv_results_)\n",
    "    print('==========================')\n",
    "    print('最佳分数：{}'.format(clf.best_score_))                                  \n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"%s: %r\" % (param_name, clf.best_params_[param_name]))\n",
    "        \n",
    "pipecv_report(gds,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 1.53638665,  0.84108337,  1.50498199,  0.92185648,  1.52556356,\n",
      "        0.82376011,  1.64792975,  0.8337481 ,  6.36994457,  3.83574422,\n",
      "        6.57771293,  4.17647401,  6.18644985,  3.82011867,  6.60001938,\n",
      "        3.88361549]), 'std_fit_time': array([ 0.13098273,  0.00402166,  0.01310658,  0.01742596,  0.00862673,\n",
      "        0.01572789,  0.01140954,  0.01976063,  0.02655417,  0.03316774,\n",
      "        0.04260522,  0.02093559,  0.02895938,  0.04493861,  0.03124613,\n",
      "        0.01628592]), 'mean_score_time': array([ 0.30960663,  0.30783129,  0.31347855,  0.30852087,  0.31317782,\n",
      "        0.30119602,  0.30119292,  0.29755076,  0.74135272,  0.73238977,\n",
      "        0.70478511,  0.70545093,  0.70644848,  0.72674378,  0.73271187,\n",
      "        0.71177681]), 'std_score_time': array([ 0.00493704,  0.01222322,  0.00576236,  0.0094468 ,  0.01078897,\n",
      "        0.00705274,  0.00895726,  0.0061035 ,  0.05998034,  0.0237488 ,\n",
      "        0.01506885,  0.02044336,  0.01439122,  0.01024166,  0.00541939,\n",
      "        0.01218001]), 'param_step1__ngram_range': masked_array(data = [(1, 1) (1, 1) (1, 1) (1, 1) (1, 1) (1, 1) (1, 1) (1, 1) (1, 2) (1, 2)\n",
      " (1, 2) (1, 2) (1, 2) (1, 2) (1, 2) (1, 2)],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__alpha': masked_array(data = [0.0001 0.0001 0.0001 0.0001 1e-05 1e-05 1e-05 1e-05 0.0001 0.0001 0.0001\n",
      " 0.0001 1e-05 1e-05 1e-05 1e-05],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__loss': masked_array(data = ['hinge' 'hinge' 'modified_huber' 'modified_huber' 'hinge' 'hinge'\n",
      " 'modified_huber' 'modified_huber' 'hinge' 'hinge' 'modified_huber'\n",
      " 'modified_huber' 'hinge' 'hinge' 'modified_huber' 'modified_huber'],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_step2__penalty': masked_array(data = ['l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1'\n",
      " 'l2'],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'step1__ngram_range': (1, 1), 'step2__alpha': 0.0001, 'step2__loss': 'hinge', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.0001, 'step2__loss': 'hinge', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.0001, 'step2__loss': 'modified_huber', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 0.0001, 'step2__loss': 'modified_huber', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 1e-05, 'step2__loss': 'hinge', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 1e-05, 'step2__loss': 'hinge', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 1e-05, 'step2__loss': 'modified_huber', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 1), 'step2__alpha': 1e-05, 'step2__loss': 'modified_huber', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.0001, 'step2__loss': 'hinge', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.0001, 'step2__loss': 'hinge', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.0001, 'step2__loss': 'modified_huber', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 0.0001, 'step2__loss': 'modified_huber', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 1e-05, 'step2__loss': 'hinge', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 1e-05, 'step2__loss': 'hinge', 'step2__penalty': 'l2'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 1e-05, 'step2__loss': 'modified_huber', 'step2__penalty': 'l1'}, {'step1__ngram_range': (1, 2), 'step2__alpha': 1e-05, 'step2__loss': 'modified_huber', 'step2__penalty': 'l2'}], 'split0_test_score': array([ 0.79213483,  0.84831461,  0.79962547,  0.84456929,  0.8071161 ,\n",
      "        0.84456929,  0.80524345,  0.8071161 ,  0.81835206,  0.83520599,\n",
      "        0.8164794 ,  0.83707865,  0.81835206,  0.83707865,  0.80524345,\n",
      "        0.82397004]), 'split1_test_score': array([ 0.81988743,  0.81988743,  0.83114447,  0.83489681,  0.82551595,\n",
      "        0.83302064,  0.80300188,  0.81801126,  0.82551595,  0.8424015 ,\n",
      "        0.82739212,  0.84052533,  0.82926829,  0.84427767,  0.81238274,\n",
      "        0.77485929]), 'split2_test_score': array([ 0.78986867,  0.80863039,  0.77861163,  0.81050657,  0.80487805,\n",
      "        0.80487805,  0.81425891,  0.77485929,  0.79362101,  0.8217636 ,\n",
      "        0.79549719,  0.81238274,  0.79737336,  0.82363977,  0.8011257 ,\n",
      "        0.74108818]), 'mean_test_score': array([ 0.800625,  0.825625,  0.803125,  0.83    ,  0.8125  ,  0.8275  ,\n",
      "        0.8075  ,  0.8     ,  0.8125  ,  0.833125,  0.813125,  0.83    ,\n",
      "        0.815   ,  0.835   ,  0.80625 ,  0.78    ]), 'std_test_score': array([ 0.01364562,  0.01670326,  0.02158233,  0.01433236,  0.00924463,\n",
      "        0.01666949,  0.00486392,  0.01831725,  0.01366006,  0.00855056,\n",
      "        0.01323172,  0.01253072,  0.01323142,  0.00855028,  0.00464914,\n",
      "        0.03403613]), 'rank_test_score': array([14,  6, 13,  3,  9,  5, 11, 15,  9,  2,  8,  3,  7,  1, 12, 16]), 'split0_train_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.99718574,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split1_train_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.99906279,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'split2_train_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.99906279,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'mean_train_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.99843711,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]), 'std_train_score': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00088485,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,  0.        ])}\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "#运行pipe2 要reload dataset\n",
    "pipe_2 = Pipeline([('step1',TfidfVectorizer()), ('step2', SGDClassifier(random_state=940302,\n",
    "                                           max_iter=200, tol=None))])\n",
    "pipe_2_params={'step1__ngram_range':[(1,1),(1,2)],\n",
    "                'step2__alpha': (1e-4,1e-5),\n",
    "              'step2__loss':('hinge','modified_huber'),\n",
    "              'step2__penalty':('l1','l2'),    \n",
    "       }\n",
    "gds_2 = GridSearchCV(estimator=pipe_2,param_grid=pipe_2_params)\n",
    "gds_2 = gds_2.fit(docs_train,y_train)\n",
    "print(gds_2.cv_results_)\n",
    "print('==========================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳分数：0.835\n",
      "step1__ngram_range: (1, 2)\n",
      "step2__alpha: 1e-05\n",
      "step2__loss: 'hinge'\n",
      "step2__penalty: 'l2'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.76      0.81       192\n",
      "        pos       0.80      0.89      0.84       208\n",
      "\n",
      "avg / total       0.83      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('最佳分数：{}'.format(gds_2.best_score_))                                  \n",
    "for param_name in sorted(pipe_2_params.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gds_2.best_params_[param_name]))\n",
    "y_predicted = gds_2.predict(docs_test)\n",
    "print(metrics.classification_report(y_test, y_predicted,target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
