{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#importing DCS techniques from DESlib\n",
    "from deslib.dcs.ola import OLA\n",
    "from deslib.dcs.a_priori import APriori\n",
    "from deslib.dcs.mcb import MCB\n",
    "\n",
    "#import DES techniques from DESlib\n",
    "from deslib.des.des_p import DESP\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des.meta_des import METADES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理数据集\n",
    "分为三部分，训练集、模型动态选择集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "# split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the variables to have 0 mean and unit variance\n",
    "scalar = StandardScaler() # 很关键\n",
    "X_train = scalar.fit_transform(X_train) \n",
    "X_test = scalar.transform(X_test)  # 用训练数据tranform测试数据\n",
    "\n",
    "# Split the data into training and DSEL for DS techniques\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练基础分类器集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=CalibratedClassifierCV(base_estimator=Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=10, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "            cv=3, method='sigmoid'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签类别需要满足从0到L-1（L为类别总数），不满足条件的可以借助LabelEncoder\n",
    "model = CalibratedClassifierCV(Perceptron(max_iter=10))\n",
    "# Train a pool of 10 classifiers\n",
    "pool_classifiers = BaggingClassifier(model, n_estimators=10)\n",
    "pool_classifiers.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建DS模型\n",
    "唯一参数是基础训练器集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DCS techniques\n",
    "ola = OLA(pool_classifiers)\n",
    "mcb = MCB(pool_classifiers)\n",
    "apriori = APriori(pool_classifiers)\n",
    "\n",
    "# DES techniques\n",
    "knorau = KNORAU(pool_classifiers)\n",
    "kne = KNORAE(pool_classifiers)\n",
    "desp = DESP(pool_classifiers)\n",
    "meta = METADES(pool_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DS模型拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deslib.des.meta_des.METADES at 0x1a666786828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knorau.fit(X_dsel, y_dsel)\n",
    "kne.fit(X_dsel, y_dsel)\n",
    "desp.fit(X_dsel, y_dsel)\n",
    "ola.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "apriori.fit(X_dsel, y_dsel)\n",
    "meta.fit(X_dsel, y_dsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预估准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy OLA:  0.9473684210526315\n",
      "Classification accuracy A priori:  0.9473684210526315\n",
      "Classification accuracy KNORA-Union:  0.9736842105263158\n",
      "Classification accuracy KNORA-Eliminate:  0.9649122807017544\n",
      "Classification accuracy DESP:  0.9736842105263158\n",
      "Classification accuracy METADES:  0.9736842105263158\n",
      "Classification accuracy MCB:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "print('Classification accuracy OLA: ', ola.score(X_test, y_test))\n",
    "print('Classification accuracy A priori: ', apriori.score(X_test, y_test))\n",
    "print('Classification accuracy KNORA-Union: ', knorau.score(X_test, y_test))\n",
    "print('Classification accuracy KNORA-Eliminate: ', kne.score(X_test, y_test))\n",
    "print('Classification accuracy DESP: ', desp.score(X_test, y_test))\n",
    "print('Classification accuracy METADES: ', meta.score(X_test, y_test))\n",
    "print('Classification accuracy MCB: ', mcb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 轻微调参-0-\n",
    "以METADES为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (80,17) and (21,2) not aligned: 17 (dim 1) != 21 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2141009eec84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMETADES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_classifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hybrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmeta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dsel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dsel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Classification accuracy METADES: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\deslib\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    369\u001b[0m                 pred_ds = self.classify_with_ds(X_DS[ind_ds_classifier],\n\u001b[0;32m    370\u001b[0m                                                 \u001b[0mbase_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_ds_original_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m                                                 selected_probabilities)\n\u001b[0m\u001b[0;32m    372\u001b[0m                 \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_ds_original_matrix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_ds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\deslib\\des\\base.py\u001b[0m in \u001b[0;36mclassify_with_ds\u001b[1;34m(self, query, predictions, probabilities)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mcompetences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_competence_from_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mcompetences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_competence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\deslib\\des\\meta_des.py\u001b[0m in \u001b[0;36mestimate_competence_from_proba\u001b[1;34m(self, query, probabilities)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;31m# Get the probability for class 1 (Competent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mcompetences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_feature_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;31m# Reshape the array from 1D [n_samples x n_classifiers] to 2D [n_samples, n_classifiers]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict_log_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;31m# normalize by P(x) = P(f_1, ..., f_n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mlog_prob_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    726\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (80,17) and (21,2) not aligned: 17 (dim 1) != 21 (dim 0)"
     ]
    }
   ],
   "source": [
    "# meta2 = METADES(pool_classifiers,k=5) #指定k时出现ValueError: shapes (110,17) and (21,2) not aligned\n",
    "meta2 = METADES(pool_classifiers, Hc=0.8, k=5, mode='hybrid')\n",
    "meta2.fit(X_dsel, y_dsel)\n",
    "print('Classification accuracy METADES: ', meta2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "fire_mcb = MCB(pool_classifiers, DFP=True, safe_k=7)\n",
    "fire_mcb.fit(X_dsel,y_dsel)\n",
    "print(fire_mcb.score(X_test,y_test))\n",
    "print(mcb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.17134-SP0\n",
      "Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "NumPy 1.14.5\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy RF:  0.9440559440559441\n",
      "Evaluating DS techniques:\n",
      "Classification accuracy KNORAU:  0.993006993006993\n",
      "Classification accuracy KNORA-Eliminate:  1.0\n",
      "Classification accuracy DESP:  0.986013986013986\n",
      "Classification accuracy OLA:  0.9790209790209791\n",
      "Classification accuracy MCB:  0.986013986013986\n",
      "Classification accuracy META-DES:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "from deslib.dcs.ola import OLA\n",
    "from deslib.dcs.mcb import MCB\n",
    "from deslib.des.des_p import DESP\n",
    "from deslib.des.knora_u import KNORAU\n",
    "from deslib.des.meta_des import METADES\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example of a des techniques\n",
    "from deslib.des.knora_e import KNORAE\n",
    "\n",
    "# Generate a classification dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "# split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# Training a random forest to be used as the pool of classifiers. We set the maximum depth of the tree so that it\n",
    "# can estimate probabilities\n",
    "pool_classifiers = RandomForestClassifier(n_estimators=10, max_depth=5)\n",
    "pool_classifiers.fit(X_train, y_train)\n",
    "\n",
    "# Initialize a DS technique. Here we specify the size of the region of competence (5 neighbors)\n",
    "knorau = KNORAU(pool_classifiers)\n",
    "kne = KNORAE(pool_classifiers)\n",
    "desp = DESP(pool_classifiers)\n",
    "ola = OLA(pool_classifiers)\n",
    "mcb = MCB(pool_classifiers)\n",
    "meta = METADES(pool_classifiers)\n",
    "\n",
    "# Fit the DS techniques\n",
    "knorau.fit(X_dsel, y_dsel)\n",
    "kne.fit(X_dsel, y_dsel)\n",
    "desp.fit(X_dsel, y_dsel)\n",
    "meta.fit(X_dsel, y_dsel)\n",
    "ola.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "\n",
    "# Calculate classification accuracy of each technique\n",
    "print('Classification accuracy RF: ', RF.score(X_test, y_test))\n",
    "print('Evaluating DS techniques:')\n",
    "print('Classification accuracy KNORAU: ', knorau.score(X_test, y_test))\n",
    "print('Classification accuracy KNORA-Eliminate: ', kne.score(X_test, y_test))\n",
    "print('Classification accuracy DESP: ', desp.score(X_test, y_test))\n",
    "print('Classification accuracy OLA: ', ola.score(X_test, y_test))\n",
    "print('Classification accuracy MCB: ', mcb.score(X_test, y_test))\n",
    "print('Classification accuracy META-DES: ', meta.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy RF:  0.8881118881118881\n",
      "Evaluating DS techniques:\n",
      "Classification accuracy KNORAU:  0.9440559440559441\n",
      "Classification accuracy KNORA-Eliminate:  0.993006993006993\n",
      "Classification accuracy DESP:  0.9440559440559441\n",
      "Classification accuracy OLA:  0.951048951048951\n",
      "Classification accuracy MCB:  0.9790209790209791\n",
      "Classification accuracy META-DES:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "# split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X, y, test_size=0.50)\n",
    "\n",
    "# Training a random forest to be used as the pool of classifiers. We set the maximum depth of the tree so that it\n",
    "# can estimate probabilities\n",
    "pool_classifiers = RandomForestClassifier(n_estimators=10, max_depth=5)\n",
    "pool_classifiers.fit(X_train, y_train)\n",
    "\n",
    "# Initialize a DS technique. Here we specify the size of the region of competence (5 neighbors)\n",
    "knorau = KNORAU(pool_classifiers,k=5)\n",
    "kne = KNORAE(pool_classifiers, k=5)\n",
    "desp = DESP(pool_classifiers, k=5)\n",
    "ola = OLA(pool_classifiers, k=5)\n",
    "mcb = MCB(pool_classifiers, k=5)\n",
    "meta = METADES(pool_classifiers)\n",
    "\n",
    "# Fit the DS techniques\n",
    "knorau.fit(X_dsel, y_dsel)\n",
    "kne.fit(X_dsel, y_dsel)\n",
    "desp.fit(X_dsel, y_dsel)\n",
    "meta.fit(X_dsel, y_dsel)\n",
    "ola.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "\n",
    "# Calculate classification accuracy of each technique\n",
    "print('Classification accuracy RF: ', RF.score(X_test, y_test))\n",
    "print('Evaluating DS techniques:')\n",
    "print('Classification accuracy KNORAU: ', knorau.score(X_test, y_test))\n",
    "print('Classification accuracy KNORA-Eliminate: ', kne.score(X_test, y_test))\n",
    "print('Classification accuracy DESP: ', desp.score(X_test, y_test))\n",
    "print('Classification accuracy OLA: ', ola.score(X_test, y_test))\n",
    "print('Classification accuracy MCB: ', mcb.score(X_test, y_test))\n",
    "print('Classification accuracy META-DES: ', meta.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不同的base learner\n",
    "结果都很糟糕\n",
    "最好的步骤是：\n",
    "- 先用gridsearch，cv找单个模型的最好参数\n",
    "- 训练几个表现不错的base learner之后再用stacking方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In this example we show that the framework can also be used using different classifier models in the pool\n",
    "of classifiers. Such pool of classifiers are called Heterogeneous.\n",
    "Here we consider a pool of classifiers composed of a Gaussian Naive Bayes, Perceptron, k-NN, Decision tree\n",
    "Linear SVM and Gaussian SVM\n",
    "'''\n",
    "\n",
    "# Importing dynamic selection techniques:\n",
    "from deslib.dcs.a_posteriori import APosteriori\n",
    "from deslib.dcs.mcb import MCB\n",
    "from deslib.dcs.lca import LCA\n",
    "from deslib.des.probabilistic import RRC\n",
    "from deslib.des.knop import KNOP\n",
    "from deslib.des.knora_e import KNORAE\n",
    "\n",
    "# Base classifier models:\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Importing dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# Generate a classification dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "# Scale the variables to have 0 mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Split the data into training and DSEL for DS techniques\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# 基础学习器都太弱了，不是全0就是全1\n",
    "# STACKING有用的基础是，base learner表现好而不同\n",
    "model_perceptron = CalibratedClassifierCV(Perceptron(max_iter=100)).fit(X_train, y_train)\n",
    "model_linear_svm = CalibratedClassifierCV(LinearSVC()).fit(X_train, y_train)\n",
    "model_svc = SVC(probability=True).fit(X_train, y_train)\n",
    "model_bayes = GaussianNB().fit(X_train, y_train)\n",
    "model_tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "pool_classifiers = [model_perceptron, model_linear_svm, model_svc, model_bayes, model_tree, model_knn]\n",
    "\n",
    "# Initializing the DS techniques\n",
    "knop = KNOP(pool_classifiers)\n",
    "rrc = RRC(pool_classifiers)\n",
    "lca = LCA(pool_classifiers)\n",
    "mcb = MCB(pool_classifiers)\n",
    "aposteriori = APosteriori(pool_classifiers)\n",
    "\n",
    "# Fitting the techniques\n",
    "knop.fit(X_dsel, y_dsel)\n",
    "rrc.fit(X_dsel, y_dsel)\n",
    "lca.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "aposteriori.fit(X_dsel, y_dsel)\n",
    "# print(\"base learners' score:\")\n",
    "# print('bayes:',model_bayes.score(X_test,y_test))\n",
    "# print('knn:',model_knn.score(X_test,y_test))\n",
    "# print('Linear SVM:',model_linear_svm.score(X_test,y_test))\n",
    "# print('perceptron:',model_perceptron.score(X_test,y_test))\n",
    "# print('decision tree:',model_tree.score(X_test,y_test))\n",
    "# print('SVC:',model_svc.score(X_test,y_test))\n",
    "\n",
    "\n",
    "# Calculate classification accuracy of each technique\n",
    "# print('Evaluating DS techniques:')\n",
    "# print('Classification accuracy KNOP: ', knop.score(X_test, y_test))\n",
    "# print('Classification accuracy RRC: ', rrc.score(X_test, y_test))\n",
    "# print('Classification accuracy LCA: ', lca.score(X_test, y_test))\n",
    "# print('Classification accuracy MCB: ', mcb.score(X_test, y_test))\n",
    "# print('Classification accuracy A posteriori: ', aposteriori.score(X_test, y_test))\n",
    "\n",
    "model_linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "C:\\Users\\gao\\software\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_perceptron, model_linear_svm, model_svc, model_bayes, model_tree, model_knn\n",
    "# 试一下Voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "model_perceptron = CalibratedClassifierCV(Perceptron(max_iter=100)).fit(X_train, y_train)\n",
    "model_linear_svm = CalibratedClassifierCV(LinearSVC()).fit(X_train, y_train)\n",
    "model_svc = SVC(probability=True).fit(X_train, y_train)\n",
    "model_bayes = GaussianNB().fit(X_train, y_train)\n",
    "model_tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier( estimators=[('p', model_perceptron), \n",
    "                                           ('svm', model_linear_svm), \n",
    "                                           ('svc', model_svc),\n",
    "                                           ('bayes',model_bayes),\n",
    "                                           ('decision tree',model_tree),\n",
    "                                           ('knn',model_knn)\n",
    "                                          ], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
